{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP6chF9hO/6nIXKOiMoDX3P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dinhthixuanbinh/Note/blob/main/Yolov9_humandetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jLAPrjxyDyQ",
        "outputId": "24f898be-d1fd-4e71-f46e-3a64edb9ce1c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SW4pWMMnoE8x",
        "outputId": "27e9a8f3-976b-4cd8-b26f-6c31836811e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov9'...\n",
            "remote: Enumerating objects: 547, done.\u001b[K\n",
            "remote: Counting objects: 100% (168/168), done.\u001b[K\n",
            "remote: Compressing objects: 100% (66/66), done.\u001b[K\n",
            "remote: Total 547 (delta 132), reused 102 (delta 102), pack-reused 379\u001b[K\n",
            "Receiving objects: 100% (547/547), 2.91 MiB | 17.73 MiB/s, done.\n",
            "Resolving deltas: 100% (193/193), done.\n",
            "/content/yolov9\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/WongKinYiu/yolov9.git\n",
        "%cd yolov9\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! wget https://github.com/WongKinYiu/yolov9/releases/download/v0.1/yolov9-c.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbHwDgRqoNJB",
        "outputId": "3bad3909-d574-4ab9-c591-6199723d1de7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-08 06:50:08--  https://github.com/WongKinYiu/yolov9/releases/download/v0.1/yolov9-c.pt\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/759338070/c8ca43f2-0d2d-4aa3-a074-426505bfbfb1?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240308%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240308T065008Z&X-Amz-Expires=300&X-Amz-Signature=f1e52419479420ea7475ba1e6082ae7355cec585aa0c52b94d2c2c342a52af85&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=759338070&response-content-disposition=attachment%3B%20filename%3Dyolov9-c.pt&response-content-type=application%2Foctet-stream [following]\n",
            "--2024-03-08 06:50:08--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/759338070/c8ca43f2-0d2d-4aa3-a074-426505bfbfb1?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240308%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240308T065008Z&X-Amz-Expires=300&X-Amz-Signature=f1e52419479420ea7475ba1e6082ae7355cec585aa0c52b94d2c2c342a52af85&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=759338070&response-content-disposition=attachment%3B%20filename%3Dyolov9-c.pt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 103153312 (98M) [application/octet-stream]\n",
            "Saving to: ‘yolov9-c.pt.1’\n",
            "\n",
            "yolov9-c.pt.1       100%[===================>]  98.37M   233MB/s    in 0.4s    \n",
            "\n",
            "2024-03-08 06:50:09 (233 MB/s) - ‘yolov9-c.pt.1’ saved [103153312/103153312]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip /content/drive/MyDrive/human_detection_dataset.zip"
      ],
      "metadata": {
        "id": "f_nFzQOeqH9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import yaml\n",
        "\n",
        "yaml_path = 'human_detection_dataset/data.yaml'\n",
        "label_lst = ['Human']\n",
        "data_dict = {\n",
        "    'path' : os.path.join(os.getcwd(), 'human_detection_dataset'),\n",
        "    'train' : 'train/images',\n",
        "    'val' : 'val/images',\n",
        "    'nc' : len(label_lst),\n",
        "    'names' : label_lst\n",
        "}"
      ],
      "metadata": {
        "id": "-gDioAqcqQRO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(yaml_path, 'w') as f:\n",
        "  yaml.dump(data_dict, f, sort_keys= False)"
      ],
      "metadata": {
        "id": "HCeovIyF0IMv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! python train.py --workers 8 --device 0 --batch 8 --data /content/human_detection_dataset/data.yaml --img 640 --cfg models/detect/gelan-c.yaml --weights '/content/gelan-c.pt' --name gelan-c --hyp hyp.scratch-high.yaml --min-items 0 --epochs 10 --close-mosaic 15\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNxUpIZSs0Qs",
        "outputId": "e94a7f4c-8b0a-4940-f14c-4395f04fa9cf"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-03-08 07:00:08.680839: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-08 07:00:08.680891: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-08 07:00:08.682728: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-08 07:00:09.835351: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=/content/gelan-c.pt, cfg=models/detect/gelan-c.yaml, data=/content/human_detection_dataset/data.yaml, hyp=hyp.scratch-high.yaml, epochs=10, batch_size=8, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=0, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=gelan-c, exist_ok=False, quad=False, cos_lr=False, flat_cos_lr=False, fixed_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, min_items=0, close_mosaic=15, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "YOLO 🚀 v0.1-53-g380284c Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, cls_pw=1.0, obj=0.7, obj_pw=1.0, dfl=1.5, iou_t=0.2, anchor_t=5.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.9, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.15, copy_paste=0.3\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLO 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLO 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 17.2MB/s]\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      1856  models.common.Conv                      [3, 64, 3, 2]                 \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  1    212864  models.common.RepNCSPELAN4              [128, 256, 128, 64, 1]        \n",
            "  3                -1  1    164352  models.common.ADown                     [256, 256]                    \n",
            "  4                -1  1    847616  models.common.RepNCSPELAN4              [256, 512, 256, 128, 1]       \n",
            "  5                -1  1    656384  models.common.ADown                     [512, 512]                    \n",
            "  6                -1  1   2857472  models.common.RepNCSPELAN4              [512, 512, 512, 256, 1]       \n",
            "  7                -1  1    656384  models.common.ADown                     [512, 512]                    \n",
            "  8                -1  1   2857472  models.common.RepNCSPELAN4              [512, 512, 512, 256, 1]       \n",
            "  9                -1  1    656896  models.common.SPPELAN                   [512, 512, 256]               \n",
            " 10                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 11           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 12                -1  1   3119616  models.common.RepNCSPELAN4              [1024, 512, 512, 256, 1]      \n",
            " 13                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 14           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 15                -1  1    912640  models.common.RepNCSPELAN4              [1024, 256, 256, 128, 1]      \n",
            " 16                -1  1    164352  models.common.ADown                     [256, 256]                    \n",
            " 17          [-1, 12]  1         0  models.common.Concat                    [1]                           \n",
            " 18                -1  1   2988544  models.common.RepNCSPELAN4              [768, 512, 512, 256, 1]       \n",
            " 19                -1  1    656384  models.common.ADown                     [512, 512]                    \n",
            " 20           [-1, 9]  1         0  models.common.Concat                    [1]                           \n",
            " 21                -1  1   3119616  models.common.RepNCSPELAN4              [1024, 512, 512, 256, 1]      \n",
            " 22      [15, 18, 21]  1   5491411  models.yolo.DDetect                     [1, [256, 512, 512]]          \n",
            "gelan-c summary: 621 layers, 25437843 parameters, 25437827 gradients\n",
            "\n",
            "Transferred 931/937 items from /content/gelan-c.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 154 weight(decay=0.0), 161 weight(decay=0.0005), 160 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/human_detection_dataset/train/labels... 2220 images, 0 backgrounds, 0 corrupt: 100% 2220/2220 [00:04<00:00, 496.07it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/human_detection_dataset/train/labels.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/human_detection_dataset/val/labels... 1642 images, 0 backgrounds, 0 corrupt: 100% 1642/1642 [00:01<00:00, 1173.06it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/human_detection_dataset/val/labels.cache\n",
            "Plotting labels to runs/train/gelan-c/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/gelan-c\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "        0/9      8.11G     0.9755     0.8788      1.049         39        640: 100% 278/278 [06:05<00:00,  1.32s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 103/103 [01:10<00:00,  1.45it/s]\n",
            "                   all       1642      13171      0.879      0.793      0.883      0.653\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "        1/9       8.6G     0.9617     0.6726      1.031         83        640: 100% 278/278 [05:48<00:00,  1.25s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 103/103 [01:08<00:00,  1.51it/s]\n",
            "                   all       1642      13171      0.847      0.744      0.845        0.6\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "        2/9       8.6G      1.027     0.7097      1.049         81        640: 100% 278/278 [05:51<00:00,  1.26s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 103/103 [01:08<00:00,  1.51it/s]\n",
            "                   all       1642      13171      0.882      0.746      0.853      0.591\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "        3/9       8.6G      1.043     0.6906      1.056         56        640: 100% 278/278 [05:47<00:00,  1.25s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 103/103 [01:07<00:00,  1.54it/s]\n",
            "                   all       1642      13171      0.834      0.741      0.839      0.574\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "        4/9      9.09G      1.047     0.6928      1.061         75        640: 100% 278/278 [05:46<00:00,  1.25s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 103/103 [01:09<00:00,  1.49it/s]\n",
            "                   all       1642      13171      0.855      0.746      0.846       0.57\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "        5/9      9.09G      1.012     0.6614      1.048         50        640: 100% 278/278 [05:44<00:00,  1.24s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 103/103 [01:05<00:00,  1.57it/s]\n",
            "                   all       1642      13171      0.872      0.749      0.853      0.594\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "        6/9      9.09G     0.9877     0.6284      1.042         49        640: 100% 278/278 [05:40<00:00,  1.23s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 103/103 [01:08<00:00,  1.50it/s]\n",
            "                   all       1642      13171      0.857      0.741      0.849      0.593\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "        7/9      9.09G     0.9454     0.6055      1.024        128        640: 100% 278/278 [05:37<00:00,  1.21s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 103/103 [01:06<00:00,  1.55it/s]\n",
            "                   all       1642      13171      0.855       0.76       0.86      0.613\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "        8/9      9.09G     0.9196     0.5821      1.011         83        640: 100% 278/278 [05:37<00:00,  1.21s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 103/103 [01:06<00:00,  1.55it/s]\n",
            "                   all       1642      13171      0.866      0.777      0.867       0.62\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "        9/9      9.09G     0.8962      0.566      1.005         48        640: 100% 278/278 [05:44<00:00,  1.24s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 103/103 [01:10<00:00,  1.47it/s]\n",
            "                   all       1642      13171      0.863      0.771      0.863      0.617\n",
            "\n",
            "10 epochs completed in 1.159 hours.\n",
            "Optimizer stripped from runs/train/gelan-c/weights/last.pt, saved as runs/train/gelan-c/weights/last_striped.pt, 51.4MB\n",
            "Optimizer stripped from runs/train/gelan-c/weights/best.pt, saved as runs/train/gelan-c/weights/best_striped.pt, 51.4MB\n",
            "\n",
            "Validating runs/train/gelan-c/weights/best.pt...\n",
            "Fusing layers... \n",
            "gelan-c summary: 387 layers, 25227859 parameters, 0 gradients\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 103/103 [01:15<00:00,  1.36it/s]\n",
            "                   all       1642      13171      0.879      0.793      0.883      0.653\n",
            "Results saved to \u001b[1mruns/train/gelan-c\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python val.py --data /content/human_detection_dataset/data.yaml --img 640 --batch 8 --conf 0.001 --iou 0.7 --device 0 --weights '/content/yolov9/runs/train/gelan-c/weights/best.pt' --save-json --name gelan_c_640_val"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ix1ZwdqFBsH",
        "outputId": "4fe64ea6-7245-4851-a31e-5ac1e085307d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mdata=/content/human_detection_dataset/data.yaml, weights=['/content/yolov9/runs/train/gelan-c/weights/best.pt'], batch_size=8, imgsz=640, conf_thres=0.001, iou_thres=0.7, max_det=300, task=val, device=0, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=True, project=runs/val, name=gelan_c_640_val, exist_ok=False, half=False, dnn=False, min_items=0\n",
            "YOLO 🚀 v0.1-53-g380284c Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "gelan-c summary: 387 layers, 25227859 parameters, 0 gradients\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/human_detection_dataset/val/labels.cache... 1642 images, 0 backgrounds, 0 corrupt: 100% 1642/1642 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 206/206 [01:21<00:00,  2.52it/s]\n",
            "                   all       1642      13171      0.877      0.794      0.883      0.654\n",
            "Speed: 0.2ms pre-process, 19.0ms inference, 2.8ms NMS per image at shape (8, 3, 640, 640)\n",
            "\n",
            "Evaluating pycocotools mAP... saving runs/val/gelan_c_640_val/best_predictions.json...\n",
            "loading annotations into memory...\n",
            "pycocotools unable to run: [Errno 2] No such file or directory: '/content/human_detection_dataset/annotations/instances_val2017.json'\n",
            "Results saved to \u001b[1mruns/val/gelan_c_640_val\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --img 640 --conf 0.6 --weights '/content/yolov9/runs/train/gelan-c/weights/best.pt' --data /content/human_detection_dataset/data.yaml --source https://m.media-amazon.com/images/M/MV5BOWIyZTdkYjktZjkxMC00YjRlLWJmMjItNjg2M2IyYzJjMTY2XkEyXkFqcGdeQWRvb2xpbmhk._V1_.jpg\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtjkZNotJ4KX",
        "outputId": "a27c202a-6087-4067-c19e-91d01a327267"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/yolov9/runs/train/gelan-c/weights/best.pt'], source=https://m.media-amazon.com/images/M/MV5BOWIyZTdkYjktZjkxMC00YjRlLWJmMjItNjg2M2IyYzJjMTY2XkEyXkFqcGdeQWRvb2xpbmhk._V1_.jpg, data=/content/human_detection_dataset/data.yaml, imgsz=[640, 640], conf_thres=0.6, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m YOLO requirements \"gitpython\" \"ipython\" not found, attempting AutoUpdate...\n",
            "Collecting gitpython\n",
            "  Downloading GitPython-3.1.42-py3-none-any.whl (195 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 195.4/195.4 kB 2.3 MB/s eta 0:00:00\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (7.34.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.7/62.7 kB 7.8 MB/s eta 0:00:00\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 16.4 MB/s eta 0:00:00\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython) (4.9.0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython) (0.2.13)\n",
            "Installing collected packages: smmap, jedi, gitdb, gitpython\n",
            "Successfully installed gitdb-4.0.11 gitpython-3.1.42 jedi-0.19.1 smmap-5.0.1\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m 2 packages updated per /content/yolov9/requirements.txt\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "Downloading https://m.media-amazon.com/images/M/MV5BOWIyZTdkYjktZjkxMC00YjRlLWJmMjItNjg2M2IyYzJjMTY2XkEyXkFqcGdeQWRvb2xpbmhk._V1_.jpg to MV5BOWIyZTdkYjktZjkxMC00YjRlLWJmMjItNjg2M2IyYzJjMTY2XkEyXkFqcGdeQWRvb2xpbmhk._V1_.jpg...\n",
            "100% 288k/288k [00:00<00:00, 8.85MB/s]\n",
            "YOLO 🚀 v0.1-53-g380284c Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "gelan-c summary: 387 layers, 25227859 parameters, 0 gradients\n",
            "image 1/1 /content/yolov9/MV5BOWIyZTdkYjktZjkxMC00YjRlLWJmMjItNjg2M2IyYzJjMTY2XkEyXkFqcGdeQWRvb2xpbmhk._V1_.jpg: 384x640 3 Humans, 179.8ms\n",
            "Speed: 0.7ms pre-process, 179.8ms inference, 671.5ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/exp\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UCrM5zSqK2Cc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}